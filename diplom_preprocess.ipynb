{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing pipeline for UN Parallel Corpus"
      ],
      "metadata": {
        "id": "zpSuwp7zs8R2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx34dwqhj9TQ",
        "outputId": "23b8da56-0af2-47b4-ead6-6f044e49db5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diplom'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 18 (delta 3), reused 17 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (18/18), 863.80 KiB | 3.75 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AlexSkrn/diplom.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# combine 3 source files into a single tab-delimited file\n",
        "!paste diplom/data/10K_en.txt \\\n",
        "       diplom/data/10K_ru.txt \\\n",
        "       diplom/data/10K_ids.txt \\\n",
        "       > diplom/data/combined.txt"
      ],
      "metadata": {
        "id": "TIVyA3HukHkL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -2 diplom/data/combined.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1BvTxDXnbt0",
        "outputId": "9aca4972-1853-453b-9e9d-f1044395519b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNITED NATIONS\tОБЪЕДИНЕННЫХ НАЦИЙ\t1990/trans/wp_29/1999/14/add_1 en:1:1 en:2:1 ru:2:1\n",
            "E\tE\t1990/trans/wp_29/1999/14/add_1 en:3:1 ru:3:1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l diplom/data/combined.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JT6VeXRne6j",
        "outputId": "f4737f2b-a75d-4b80-8822-158ea5d59c6c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000 diplom/data/combined.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use awk to delete duplicates, w/o changing the order of elements\n",
        "# it uses the first two columns to filter out duplicates\n",
        "!awk -F\"\\t\" '!seen[$1, $2]++' \\\n",
        "    diplom/data/combined.txt \\\n",
        "    > diplom/data/combined2.txt\n",
        "\n",
        "!wc -l diplom/data/combined2.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo1q5BMsn6pS",
        "outputId": "495edbb4-8d5d-4e4a-d9c9-c496aa880235"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9495 diplom/data/combined2.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# strip some numerals from the right-hand side of each line\n",
        "# and then run duplicate removal code again\n",
        "from diplom.rstrip_numerals import main\n",
        "\n",
        "src_file = 'diplom/data/combined2.txt'\n",
        "trg_file = 'diplom/data/combined3.txt'\n",
        "\n",
        "main(src_file, trg_file)\n",
        "\n",
        "!awk -F\"\\t\" '!seen[$1, $2]++' \\\n",
        "    diplom/data/combined3.txt \\\n",
        "    > diplom/data/uniq.txt\n",
        "\n",
        "!wc -l diplom/data/uniq.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PFDBTrBpXvs",
        "outputId": "e1dbebd9-1c39-4d72-ba91-f3df1e5a47bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 9495 lines in diplom/data/combined2.txt\n",
            "Wrote processed lines to diplom/data/combined3.txt\n",
            "8853 diplom/data/uniq.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run preprocessing steps:\n",
        "#   remove short sentences, numericals only and punctuation only\n",
        "from diplom.preprocess import main\n",
        "\n",
        "src_file = 'diplom/data/uniq.txt'\n",
        "line_nums_file = 'diplom/data/preproc_linenums.txt'\n",
        "trg_file = 'diplom/data/preproc.txt'\n",
        "\n",
        "main(src_file, line_nums_file)\n",
        "\n",
        "!awk 'NR == FNR {pos[$1]; next} FNR in pos' \\\n",
        "    diplom/data/preproc_linenums.txt \\\n",
        "    diplom/data/uniq.txt \\\n",
        "    > diplom/data/preproc.txt\n",
        "\n",
        "!wc -l \"$trg_file\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ti-cuGDHqfLE",
        "outputId": "a7abfee2-f31d-45ce-911f-d5d6447f5d06"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 8853 lines in file diplom/data/uniq.txt\n",
            "Found 128 to be removed.\n",
            "Indices (starting with 1) of lines to be kept are written to diplom/data/preproc_linenums.txt\n",
            "8725 diplom/data/preproc.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove near duplicate pairs of sentences\n",
        "from diplom.jaro_pairs_sumbyte import main\n",
        "\n",
        "source_path = 'diplom/data/preproc.txt'\n",
        "path_for_jaro = 'diplom/data/jaro_pair_scores.txt'\n",
        "path_good_numbers = 'diplom/data/jaro_good_nums.txt'\n",
        "path_bad_numbers = 'diplom/data/jaro_bad_nums.txt'\n",
        "\n",
        "main(source_path, path_for_jaro, path_good_numbers, path_bad_numbers)\n",
        "\n",
        "trg_file = 'diplom/data/jaro_pairs.txt'\n",
        "\n",
        "!awk 'NR == FNR {pos[$1]; next} FNR in pos' \\\n",
        "    'diplom/data/jaro_good_nums.txt' \\\n",
        "    'diplom/data/preproc.txt' \\\n",
        "    > 'diplom/data/jaro_pairs.txt'\n",
        "\n",
        "!wc -l \"$trg_file\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POoeUQzhujxr",
        "outputId": "4f0a9732-3d53-459c-a605-611d826c9182"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read diplom/data/preproc.txt\n",
            "Wrote 8725 jaro scores to diplom/data/jaro_pair_scores.txt\n",
            "Found 67 sentence pairs to be removed.\n",
            "Indices (starting with 1) of lines to be kept are written to diplom/data/jaro_good_nums.txt\n",
            "Use: awk 'NR == FNR {pos[$1]; next} FNR in pos' linenumbers sourcefile > targetfile.\n",
            "Indices (starting with 1) of lines to be removed are written to diplom/data/jaro_bad_nums.txt\n",
            "Use: awk 'NR == FNR {pos[$1]; next} FNR in pos' linenumbers sourcefile > targetfile.\n",
            "8658 diplom/data/jaro_pairs.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove near duplicate lines\n",
        "from diplom.jaro_lines_sumbytes import main\n",
        "\n",
        "source_path = 'diplom/data/jaro_pairs.txt'\n",
        "path_for_near_duplicates = 'diplom/data/see_sents_to_del.txt'\n",
        "path_for_del_numbers = 'diplom/data/sentences_to_del_numbers.txt'\n",
        "path_for_del_dict = 'diplom/data/sentences_to_del_numbers_dict.txt'\n",
        "\n",
        "test = False\n",
        "\n",
        "main(\n",
        "    source_path,\n",
        "     path_for_near_duplicates,\n",
        "     path_for_del_numbers,\n",
        "     path_for_del_dict,\n",
        "     test\n",
        "     )\n",
        "\n",
        "from diplom.filter_by_linenumber import filter_by_linenumber\n",
        "\n",
        "source_path = 'diplom/data/jaro_pairs.txt'\n",
        "target_path = 'diplom/data/jaro_lines.txt'\n",
        "\n",
        "filter_by_linenumber(path_for_del_numbers, source_path, target_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEWBVBSKzF5y",
        "outputId": "70c92f9b-513d-4fff-c381-17bf5a115587"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------ Iteration 0 ---------\n",
            "Sums counter: 5000\n",
            "Shape of abs diff array: (5000, 5000)\n",
            "Number of keys in sim dict: 1820\n",
            "# of sent line numbers in sim dict (keys+vals): 2897\n",
            "Dict of string sentences contains 2897 concatenated sents\n",
            "------ Iteration 1 ---------\n",
            "Sums counter: 3658\n",
            "Shape of abs diff array: (3658, 3658)\n",
            "Number of keys in sim dict: 742\n",
            "# of sent line numbers in sim dict (keys+vals): 1306\n",
            "Dict of string sentences contains 1306 concatenated sents\n",
            "------ Iteration 2 ---------\n",
            "Number of sentences to delete: 179\n",
            "Wrote 179 numbers of lines to be deleted to diplom/data/sentences_to_del_numbers.txt\n",
            "Use filter_by_linenumber.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the end of pre-processing\n",
        "!wc -l diplom/data/jaro_lines.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quIv7NKY4aJF",
        "outputId": "dda4d19b-ceff-461a-ffac-afb84784d994"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8479 diplom/data/jaro_lines.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# additional step, not related to preprocessing\n",
        "# it is splitting single file into multiple files\n",
        "# it is intended for use within dtSearch software\n",
        "# you need to create a target folder first\n",
        "from diplom.tsv import main\n",
        "\n",
        "!mkdir diplom/data/tsv_ru\n",
        "\n",
        "tsv_folder = 'diplom/data/tsv_ru'  # create this first\n",
        "file_name = 'diplom/data/jaro_lines.txt'\n",
        "data_folder = ''\n",
        "\n",
        "main(file_name, data_folder, tsv_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx0Ja5ty5IU6",
        "outputId": "80fb2ec9-7289-4ad5-d0de-6f0dc26494af"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary length is 68\n",
            "Total lines read from original files: 8479\n",
            "Total lines written to all files: 8479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -qq -r diplom/data/en_ru.zip diplom/data/tsv_ru"
      ],
      "metadata": {
        "id": "iciaJvxfyLVz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('diplom/data/en_ru.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VFao3xcq0YL6",
        "outputId": "ab4aff7f-d80b-419b-fb04-e7a2bd868530"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4ee961ee-8ff1-41c9-bc3b-a8ae821d2dd9\", \"en_ru.zip\", 963525)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jnMXFEi50mmq"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}